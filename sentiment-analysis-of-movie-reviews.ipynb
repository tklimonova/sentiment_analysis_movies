{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords, wordnet \n",
    "from nltk import word_tokenize, WordNetLemmatizer, sent_tokenize\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>first think another Disney movie, might good, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Put aside Dr. House repeat missed, Desperate H...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>big fan Stephen King's work, film made even gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>watched horrid thing TV. Needless say one movi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>truly enjoyed film. acting terrific plot. Jeff...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>memory \"The Last Hunt\" stuck since saw 1956 13...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Shakespeare fan, appreciate Ken Branagh done b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>privilege watching Scarface big screen beautif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>real classic. shipload sailors trying get town...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Serials short subjects originally shown theate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       SentimentText  Sentiment\n",
       "0  first think another Disney movie, might good, ...          1\n",
       "1  Put aside Dr. House repeat missed, Desperate H...          0\n",
       "2  big fan Stephen King's work, film made even gr...          1\n",
       "3  watched horrid thing TV. Needless say one movi...          0\n",
       "4  truly enjoyed film. acting terrific plot. Jeff...          1\n",
       "5  memory \"The Last Hunt\" stuck since saw 1956 13...          1\n",
       "6  Shakespeare fan, appreciate Ken Branagh done b...          0\n",
       "7  privilege watching Scarface big screen beautif...          1\n",
       "8  real classic. shipload sailors trying get town...          1\n",
       "9  Serials short subjects originally shown theate...          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"dataset.csv\", encoding=\"latin1\", chunksize=25000)\n",
    "data_df = next(data)\n",
    "data_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "",
    "_uuid": ""
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24904, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.drop_duplicates(keep='first', inplace=True)\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Are positive reviews longer?\n",
    "data_df['length_text'] = data_df.SentimentText.str.len()\n",
    "negative_df = data_df[data_df.Sentiment == 0]\n",
    "positive_df = data_df[data_df.Sentiment == 1]\n",
    "\n",
    "plt.hist(negative_df.length_text, bins=20, alpha=0.6, label='negative')\n",
    "plt.hist(positive_df.length_text, bins=20, alpha=0.6, label='positive')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel(\"Length of review (symbols)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['SentimentText_clean'] = data_df.SentimentText.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    \n",
    "    string = re.sub(r'\\<a href', ' ', string)\n",
    "    string = re.sub(r'&amp;', '', string) \n",
    "    string = re.sub(r'<br />', ' ', string)\n",
    "    string = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', string)\n",
    "    string = re.sub('\\d','', string)\n",
    "    string = re.sub(r\"can\\'t\", \"cannot\", string)\n",
    "    string = re.sub(r\"it\\'s\", \"it is\", string)\n",
    "    string = re.sub(r\"don\\'t\", \"do not\", string)\n",
    "    string = re.sub(r\"i\\'d\", \"i would\", string)\n",
    "    string = re.sub(r\"isn\\'t\", \"is not\", string)\n",
    "    string = re.sub(r\"wasn\\'t\", \"was not\", string)\n",
    "    string = re.sub(r\"i\\'m\", \"i am\", string)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['SentimentText_clean'] = data_df['SentimentText_clean'].apply(clean_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating amount of words in review\n",
    "def word_count(string):\n",
    "    words = string.split()\n",
    "    return len(words)\n",
    "data_df['sum_words'] = data_df['SentimentText_clean'].apply(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie    43420\n",
       "film     38997\n",
       "it       30566\n",
       "one      26423\n",
       "is       23453\n",
       "like     20212\n",
       "not      15896\n",
       "good     15061\n",
       "the      13884\n",
       "would    13545\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the most common words\n",
    "pd.Series(' '.join(data_df['SentimentText_clean']).split()).value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning unrelated words\n",
    "stop_words = stopwords.words('english') + ['movie', 'film', 'time', 'story', 'cinema', ]\n",
    "stop_words = set(stop_words)\n",
    "#remove_stop_words\n",
    "remove_stop_words = lambda r: [[word for word in word_tokenize(sente) if word not in stop_words] for sente in sent_tokenize(r)]\n",
    "data_df['SentimentText_tokens'] = data_df['SentimentText_clean'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding similar words by sentiment\n",
    "model = Word2Vec(\n",
    "        data_df['SentimentText_tokens'].apply(lambda x: x[0]),\n",
    "        iter=10,\n",
    "        size=16,\n",
    "        window=5,\n",
    "        min_count=5,\n",
    "        workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('entertaining', 0.8357029557228088),\n",
       " ('enjoyable', 0.815261960029602),\n",
       " ('enjoy', 0.8034292459487915),\n",
       " ('laughs', 0.75943523645401),\n",
       " ('funny', 0.7569681406021118),\n",
       " ('laugh', 0.7518032789230347),\n",
       " ('watchable', 0.7500874996185303),\n",
       " ('nice', 0.7370110750198364),\n",
       " ('good', 0.7343146800994873),\n",
       " ('scary', 0.734245777130127)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('fun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>length_text</th>\n",
       "      <th>SentimentText_clean</th>\n",
       "      <th>sum_words</th>\n",
       "      <th>SentimentText_tokens</th>\n",
       "      <th>lemmatized_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>first think another Disney movie, might good, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>314</td>\n",
       "      <td>first think another disney movie  might good  ...</td>\n",
       "      <td>50</td>\n",
       "      <td>[[first, think, another, disney, might, good, ...</td>\n",
       "      <td>first think another disney movie might good it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Put aside Dr. House repeat missed, Desperate H...</td>\n",
       "      <td>0</td>\n",
       "      <td>565</td>\n",
       "      <td>put aside dr  house repeat missed  desperate h...</td>\n",
       "      <td>81</td>\n",
       "      <td>[[put, aside, dr, house, repeat, missed, despe...</td>\n",
       "      <td>put aside dr house repeat miss desperate house...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>big fan Stephen King's work, film made even gr...</td>\n",
       "      <td>1</td>\n",
       "      <td>1268</td>\n",
       "      <td>big fan stephen king's work  film made even gr...</td>\n",
       "      <td>196</td>\n",
       "      <td>[[big, fan, stephen, king, 's, work, made, eve...</td>\n",
       "      <td>big fan stephen king's work film make even gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>watched horrid thing TV. Needless say one movi...</td>\n",
       "      <td>0</td>\n",
       "      <td>414</td>\n",
       "      <td>watched horrid thing tv  needless say one movi...</td>\n",
       "      <td>63</td>\n",
       "      <td>[[watched, horrid, thing, tv, needless, say, o...</td>\n",
       "      <td>watch horrid thing tv needless say one movie w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>truly enjoyed film. acting terrific plot. Jeff...</td>\n",
       "      <td>1</td>\n",
       "      <td>477</td>\n",
       "      <td>truly enjoyed film  acting terrific plot  jeff...</td>\n",
       "      <td>65</td>\n",
       "      <td>[[truly, enjoyed, acting, terrific, plot, jeff...</td>\n",
       "      <td>truly enjoyed film act terrific plot jeff comb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       SentimentText  Sentiment  length_text  \\\n",
       "0  first think another Disney movie, might good, ...          1          314   \n",
       "1  Put aside Dr. House repeat missed, Desperate H...          0          565   \n",
       "2  big fan Stephen King's work, film made even gr...          1         1268   \n",
       "3  watched horrid thing TV. Needless say one movi...          0          414   \n",
       "4  truly enjoyed film. acting terrific plot. Jeff...          1          477   \n",
       "\n",
       "                                 SentimentText_clean  sum_words  \\\n",
       "0  first think another disney movie  might good  ...         50   \n",
       "1  put aside dr  house repeat missed  desperate h...         81   \n",
       "2  big fan stephen king's work  film made even gr...        196   \n",
       "3  watched horrid thing tv  needless say one movi...         63   \n",
       "4  truly enjoyed film  acting terrific plot  jeff...         65   \n",
       "\n",
       "                                SentimentText_tokens  \\\n",
       "0  [[first, think, another, disney, might, good, ...   \n",
       "1  [[put, aside, dr, house, repeat, missed, despe...   \n",
       "2  [[big, fan, stephen, king, 's, work, made, eve...   \n",
       "3  [[watched, horrid, thing, tv, needless, say, o...   \n",
       "4  [[truly, enjoyed, acting, terrific, plot, jeff...   \n",
       "\n",
       "                                  lemmatized_reviews  \n",
       "0  first think another disney movie might good it...  \n",
       "1  put aside dr house repeat miss desperate house...  \n",
       "2  big fan stephen king's work film make even gre...  \n",
       "3  watch horrid thing tv needless say one movie w...  \n",
       "4  truly enjoyed film act terrific plot jeff comb...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lemmatizing words for better analysis\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "wordnet_map = {\"N\":wordnet.NOUN, \"V\":wordnet.VERB, \"J\":wordnet.ADJ, \"R\":wordnet.ADV}\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    pos_tag_text = nltk.pos_tag(text.split())\n",
    "    return ' '.join([lemmatizer.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tag_text])\n",
    "\n",
    "data_df['lemmatized_reviews'] = data_df['SentimentText_clean'].apply(lambda text: lemmatize_text(text))\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aag</th>\n",
       "      <th>aames</th>\n",
       "      <th>aamir</th>\n",
       "      <th>aamir khan</th>\n",
       "      <th>aankhen</th>\n",
       "      <th>aardman</th>\n",
       "      <th>aardman animation</th>\n",
       "      <th>aargh</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>...</th>\n",
       "      <th>zp</th>\n",
       "      <th>zsigmond</th>\n",
       "      <th>zu</th>\n",
       "      <th>zu warrior</th>\n",
       "      <th>zucco</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zuckerman</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zuniga</th>\n",
       "      <th>â½</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 103019 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aag  aames  aamir  aamir khan  aankhen  aardman  aardman animation  aargh  \\\n",
       "0    0      0      0           0        0        0                  0      0   \n",
       "1    0      0      0           0        0        0                  0      0   \n",
       "2    0      0      0           0        0        0                  0      0   \n",
       "3    0      0      0           0        0        0                  0      0   \n",
       "4    0      0      0           0        0        0                  0      0   \n",
       "\n",
       "   aaron  ab  ...  zp  zsigmond  zu  zu warrior  zucco  zucker  zuckerman  \\\n",
       "0      0   0  ...   0         0   0           0      0       0          0   \n",
       "1      0   0  ...   0         0   0           0      0       0          0   \n",
       "2      0   0  ...   0         0   0           0      0       0          0   \n",
       "3      0   0  ...   0         0   0           0      0       0          0   \n",
       "4      0   0  ...   0         0   0           0      0       0          0   \n",
       "\n",
       "   zulu  zuniga  â½  \n",
       "0     0       0   0  \n",
       "1     0       0   0  \n",
       "2     0       0   0  \n",
       "3     0       0   0  \n",
       "4     0       0   0  \n",
       "\n",
       "[5 rows x 103019 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vectorizing data with CountVectorizer\n",
    "\n",
    "y = data_df['Sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_df['lemmatized_reviews'], y, test_size=0.33, random_state=53)\n",
    "my_stop_words = ENGLISH_STOP_WORDS.union(['aaa', 'aa', 'want', 'make', 'lots','made', 'film', 'time', 'movie', 'films', 'movies', 'cinema', 'story', 'th'])\n",
    "\n",
    "vect = CountVectorizer(min_df=3, ngram_range=(1, 3), stop_words=my_stop_words)\n",
    "#creating bag of words for train and test data\n",
    "count_train = vect.fit_transform(X_train.values)\n",
    "count_test = vect.transform(X_test.values)\n",
    "\n",
    "# Create a DataFrame from the bow representation\n",
    "count_df = pd.DataFrame(count_train.toarray(), columns=vect.get_feature_names())\n",
    "count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding Sentiment column to new DataFrame\n",
    "count_df['Sentiment'] = data_df.Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8648254045504319\n",
      "[[3581  557]\n",
      " [ 554 3527]]\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes model (bag of words vectorizer)\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(count_train, y_train)\n",
    "\n",
    "#predicted tags\n",
    "pred = nb_classifier.predict(count_test)\n",
    "\n",
    "#accuracy score\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(score)\n",
    "\n",
    "#confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels = [0,1])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the review is 0\n",
      "The sentiment of the review is 1\n",
      "The sentiment of the review is 1\n",
      "The sentiment of the review is 0\n"
     ]
    }
   ],
   "source": [
    "# Let's test our model with random reviews\n",
    "review_1 = \"The movie was terrible. Even so the music was not bad, I would not reccomend to watch it.\"\n",
    "prediction_1 = nb_classifier.predict(vect.transform([review_1]))\n",
    "\n",
    "review_2 = \"Amazing actors play and a lot of humor. I really like this movie and would definetly watch it again.\"\n",
    "prediction_2 = nb_classifier.predict(vect.transform([review_2]))\n",
    "\n",
    "review_3 = \"This was such a horrible and sensitive topic to adapt to the screen but they really made the young men’s story justice.\"\n",
    "prediction_3 = nb_classifier.predict(vect.transform([review_3]))\n",
    "\n",
    "review_4 = \"They went through a lot of the backstory too quickly. Overall feels pretty low budget and characters feel like they are from 21th Century. The lore is the only interesting part.\"\n",
    "prediction_4 = nb_classifier.predict(vect.transform([review_4]))\n",
    "\n",
    "print(\"The sentiment of the review is %i\" % (prediction_1))\n",
    "print(\"The sentiment of the review is %i\" % (prediction_2))\n",
    "print(\"The sentiment of the review is %i\" % (prediction_3))\n",
    "print(\"The sentiment of the review is %i\" % (prediction_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build TfidfVectorizer \n",
    "\n",
    "y = data_df['Sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_df['lemmatized_reviews'], y, test_size=0.33, random_state=53)\n",
    "\n",
    "# Define the vectorizer and specify the arguments\n",
    "my_stop_words = ENGLISH_STOP_WORDS.union(['aaa', 'aa', 'want', 'make', 'lots','made', 'film', 'time', 'movie', 'films', 'movies', 'cinema', 'story', 'th'])\n",
    "\n",
    "vect_tfidf = TfidfVectorizer(ngram_range=(1, 3), max_features=2000, stop_words=my_stop_words)\n",
    "\n",
    "tfidf_train = vect_tfidf.fit_transform(X_train.values)\n",
    "tfidf_test = vect_tfidf.transform(X_test.values)\n",
    "\n",
    "# Transform to a data frame and specify the column names\n",
    "tfidf_df=pd.DataFrame(tfidf_train.toarray(), columns=vect_tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>absurd</th>\n",
       "      <th>abuse</th>\n",
       "      <th>academy</th>\n",
       "      <th>accent</th>\n",
       "      <th>accept</th>\n",
       "      <th>...</th>\n",
       "      <th>yes</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>young girl</th>\n",
       "      <th>young man</th>\n",
       "      <th>young woman</th>\n",
       "      <th>youth</th>\n",
       "      <th>zero</th>\n",
       "      <th>zombie</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113365</td>\n",
       "      <td>0.212867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.365834</td>\n",
       "      <td>0.114489</td>\n",
       "      <td>0.228384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abandon  ability  able  absolute  absolutely  absurd    abuse  academy  \\\n",
       "0      0.0      0.0   0.0       0.0         0.0     0.0  0.00000      0.0   \n",
       "1      0.0      0.0   0.0       0.0         0.0     0.0  0.00000      0.0   \n",
       "2      0.0      0.0   0.0       0.0         0.0     0.0  0.00000      0.0   \n",
       "3      0.0      0.0   0.0       0.0         0.0     0.0  0.11033      0.0   \n",
       "4      0.0      0.0   0.0       0.0         0.0     0.0  0.00000      0.0   \n",
       "\n",
       "   accent  accept  ...  yes  york     young  young girl  young man  \\\n",
       "0     0.0     0.0  ...  0.0   0.0  0.000000    0.000000   0.000000   \n",
       "1     0.0     0.0  ...  0.0   0.0  0.000000    0.000000   0.000000   \n",
       "2     0.0     0.0  ...  0.0   0.0  0.113365    0.212867   0.000000   \n",
       "3     0.0     0.0  ...  0.0   0.0  0.365834    0.114489   0.228384   \n",
       "4     0.0     0.0  ...  0.0   0.0  0.000000    0.000000   0.000000   \n",
       "\n",
       "   young woman  youth  zero  zombie  Sentiment  \n",
       "0          0.0    0.0   0.0     0.0        1.0  \n",
       "1          0.0    0.0   0.0     0.0        0.0  \n",
       "2          0.0    0.0   0.0     0.0        1.0  \n",
       "3          0.0    0.0   0.0     0.0        0.0  \n",
       "4          0.0    0.0   0.0     0.0        1.0  \n",
       "\n",
       "[5 rows x 2001 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding Sentiment column \n",
    "tfidf_df['Sentiment'] = data_df.Sentiment\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8437766151599951\n",
      "[[3416  722]\n",
      " [ 562 3519]]\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes model (tf-idf vectorizer)\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(tfidf_train, y_train)\n",
    "\n",
    "#predicted tags\n",
    "pred = nb_classifier.predict(tfidf_test)\n",
    "\n",
    "#accuracy score\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(score)\n",
    "\n",
    "#confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels = [0,1])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to predict topics using Latent Dirichlet Allocation (to cluster similar topics in reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorizing data with CountVectorizer\n",
    "my_stop_words = ENGLISH_STOP_WORDS.union(['aaa', 'aa', 'want', 'make', 'lots','made', 'film', 'time', 'movie', 'films', 'movies', 'cinema', 'story', 'th', 'll', 'song', 'dvd', 'mr'])\n",
    "\n",
    "vect_lda = CountVectorizer(max_df=.1, max_features=5000, stop_words=my_stop_words)\n",
    "#creating bag of words for train and test data\n",
    "X = vect_lda.fit_transform(data_df['lemmatized_reviews'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "horror laugh kill joke stupid flick\n",
      "Topic 1:\n",
      "music dance wonderful beautiful musical excellent\n",
      "Topic 2:\n",
      "series episode zombie season tv monster\n",
      "Topic 3:\n",
      "fight original art animation disney cartoon\n",
      "Topic 4:\n",
      "murder wife father son family kill\n",
      "Topic 5:\n",
      "kid child family friend home boy\n",
      "Topic 6:\n",
      "war american men black country british\n",
      "Topic 7:\n",
      "game future joe jane ben version\n",
      "Topic 8:\n",
      "book read novel japanese viewer element\n",
      "Topic 9:\n",
      "audience idea lack hour review simply\n"
     ]
    }
   ],
   "source": [
    "# LDA\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "lda = LatentDirichletAllocation(learning_method = 'online', n_components=10, random_state=123)\n",
    "X_topics = lda.fit_transform(X)\n",
    "X_text_c_feature_names = vect_lda.get_feature_names()\n",
    "\n",
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print (\"Topic %d:\" % (topic_idx))\n",
    "        print (\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "\n",
    "n_top_words = 6\n",
    "display_topics(lda, X_text_c_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Family movie #1:\n",
      "Ever since remember, loved airplanes flying. college private pilot's license looking become commercial. could never remember obsessed subject came across old Tail Spin tapes basement home hit me, it. parents bought every single tape show would watch kid. theme memorized grew still re-cite today. absolutely amazing plan buying DVD's soon! really great children adults absolutely timeless. cannot get enough show. ...\n",
      "\n",
      "Family movie #2:\n",
      "started watching show said \"Oh, no! It's corny Elfen Lied even bloody!\". indeed, setup almost identical, single young boy living big house himself, suddenly getting involved fantastic adventure sexy young girls come live him.<br /><br />But resemblance stops. love story almost subtle intense one Inuiyasha, childish remarks behaviors few. magical setup bit corny, it's seven people, seven servants, fighting Holy Grail, servants someone famous, half masters school, rules engagement, etc. However, s ...\n",
      "\n",
      "Family movie #3:\n",
      "I'm big fan fan film noir, film Otto Preminger easily stands one best I've seen! Preminger reunited two stars hit 'Laura' - Gene Tierney Dana Andrews, entirely different sort crime film. Laura based around love, film based around hate; watch police detective Mark Dixon, copper already suffering scrutiny superiors heavy handed tactics, accidentally kill suspect try pin murder known criminal; man name Tommy Scalisi. plot brilliantly worked, Preminger excellently balances several plot points; comes ...\n"
     ]
    }
   ],
   "source": [
    "#let's look at original reviews in Family topic\n",
    "family = X_topics[:, 5].argsort()[::-1]\n",
    "for iter_idx, movie_idx in enumerate(family[:3]):\n",
    "  print('\\nFamily movie #%d:' % (iter_idx +1))\n",
    "  print(data_df['SentimentText'][movie_idx][:500], '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
